{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0f7be44ff6d022abcdd56ca5d84b9c7c57bcc1116775f704a69faf25b23490917",
   "display_name": "Python 3.8.8 64-bit ('ai': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Flatten,Dense,Dropout,MaxPool2D,Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 4487 images belonging to 24 classes.\nFound 485 images belonging to 24 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale= 1./255, shear_range= 0.2,zoom_range=0.1,horizontal_flip=True,validation_split=0.1)\n",
    "train_data = datagen.flow_from_directory('D://AI ML DL//SLD//Data_set//ISL_new',target_size=(64,64),batch_size=32,class_mode='categorical',seed =10,subset='training')\n",
    "\n",
    "validation_data = datagen.flow_from_directory('D://AI ML DL//SLD//Data_set//ISL_new',target_size=(64,64),class_mode='categorical',batch_size=32,seed =10,subset='validation')\n",
    "\n",
    "\n",
    "#test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#test_data = test_datagen.flow_from_directory('D:/AI ML DL/SLD/data_test',target_size=(128,128),batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x1b29fcb1e50>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "model=Sequential()\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),input_shape=(64,64,3),activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "#model.add(Conv2D(filters=128,kernel_size=(3,3),activation='relu'))\n",
    "#model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "#model.add(Dense(units=64 , activation='relu'))\n",
    "#model.add(Dense(units=128 , activation='relu'))\n",
    "model.add(Dense(units=128 , activation='relu'))\n",
    "model.add(Dense(units=24 , activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 62, 62, 64)        1792      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 31, 31, 64)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 29, 29, 32)        18464     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 6272)              0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               802944    \n_________________________________________________________________\ndense_1 (Dense)              (None, 24)                3096      \n=================================================================\nTotal params: 826,296\nTrainable params: 826,296\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/25\n",
      "141/141 [==============================] - 49s 345ms/step - loss: 0.0272 - accuracy: 0.9929 - val_loss: 1.1575 - val_accuracy: 0.7588\n",
      "Epoch 2/25\n",
      "141/141 [==============================] - 49s 351ms/step - loss: 0.0307 - accuracy: 0.9902 - val_loss: 1.3245 - val_accuracy: 0.7340\n",
      "Epoch 3/25\n",
      "141/141 [==============================] - 55s 388ms/step - loss: 0.0274 - accuracy: 0.9931 - val_loss: 1.0592 - val_accuracy: 0.7897\n",
      "Epoch 4/25\n",
      "141/141 [==============================] - 48s 343ms/step - loss: 0.0271 - accuracy: 0.9922 - val_loss: 1.1129 - val_accuracy: 0.7216\n",
      "Epoch 5/25\n",
      "141/141 [==============================] - 48s 341ms/step - loss: 0.0146 - accuracy: 0.9973 - val_loss: 1.3250 - val_accuracy: 0.7588\n",
      "Epoch 6/25\n",
      "141/141 [==============================] - 49s 347ms/step - loss: 0.0253 - accuracy: 0.9918 - val_loss: 1.1347 - val_accuracy: 0.7814\n",
      "Epoch 7/25\n",
      "141/141 [==============================] - 50s 355ms/step - loss: 0.0316 - accuracy: 0.9893 - val_loss: 1.1170 - val_accuracy: 0.7876\n",
      "Epoch 8/25\n",
      "141/141 [==============================] - 48s 339ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 1.0618 - val_accuracy: 0.7938\n",
      "Epoch 9/25\n",
      "141/141 [==============================] - 47s 330ms/step - loss: 0.0261 - accuracy: 0.9933 - val_loss: 1.1546 - val_accuracy: 0.7814\n",
      "Epoch 10/25\n",
      "141/141 [==============================] - 50s 356ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 1.2911 - val_accuracy: 0.7423\n",
      "Epoch 11/25\n",
      "141/141 [==============================] - 47s 336ms/step - loss: 0.0205 - accuracy: 0.9955 - val_loss: 1.1967 - val_accuracy: 0.7381\n",
      "Epoch 12/25\n",
      "141/141 [==============================] - 48s 341ms/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 1.4619 - val_accuracy: 0.7629\n",
      "Epoch 13/25\n",
      "141/141 [==============================] - 47s 336ms/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 1.2663 - val_accuracy: 0.8062\n",
      "Epoch 14/25\n",
      "141/141 [==============================] - 48s 338ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 1.2633 - val_accuracy: 0.8041\n",
      "Epoch 15/25\n",
      "141/141 [==============================] - 54s 381ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 1.6225 - val_accuracy: 0.7093\n",
      "Epoch 16/25\n",
      "141/141 [==============================] - 51s 359ms/step - loss: 0.0420 - accuracy: 0.9866 - val_loss: 1.4710 - val_accuracy: 0.7732\n",
      "Epoch 17/25\n",
      "141/141 [==============================] - 47s 334ms/step - loss: 0.0239 - accuracy: 0.9940 - val_loss: 0.9100 - val_accuracy: 0.8536\n",
      "Epoch 18/25\n",
      "141/141 [==============================] - 54s 382ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.7965 - val_accuracy: 0.8598\n",
      "Epoch 19/25\n",
      "141/141 [==============================] - 60s 424ms/step - loss: 0.0163 - accuracy: 0.9960 - val_loss: 1.0311 - val_accuracy: 0.8247\n",
      "Epoch 20/25\n",
      "141/141 [==============================] - 50s 357ms/step - loss: 0.0337 - accuracy: 0.9891 - val_loss: 1.0952 - val_accuracy: 0.8186\n",
      "Epoch 21/25\n",
      "141/141 [==============================] - 50s 358ms/step - loss: 0.0171 - accuracy: 0.9964 - val_loss: 0.9649 - val_accuracy: 0.8206\n",
      "Epoch 22/25\n",
      "141/141 [==============================] - 50s 352ms/step - loss: 0.0101 - accuracy: 0.9953 - val_loss: 1.5841 - val_accuracy: 0.7938\n",
      "Epoch 23/25\n",
      "141/141 [==============================] - 50s 355ms/step - loss: 0.0111 - accuracy: 0.9958 - val_loss: 1.2730 - val_accuracy: 0.8144\n",
      "Epoch 24/25\n",
      "141/141 [==============================] - 50s 352ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.9455 - val_accuracy: 0.8062\n",
      "Epoch 25/25\n",
      "141/141 [==============================] - 49s 351ms/step - loss: 0.0112 - accuracy: 0.9980 - val_loss: 1.2315 - val_accuracy: 0.8351\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x=train_data,validation_data=validation_data,epochs=25,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname =\"trained_model2.hdf5\"\n",
    "model.save(fname,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([10,  6,  4, ..., 25, 31, 13], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(test_data),axis =1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"trained_model2.hdf5\"\n",
    "model.load_weights(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([21, 20,  2, ...,  5, 16,  8], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(test_data),axis =1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'A': 0,\n",
       " 'B': 1,\n",
       " 'C': 2,\n",
       " 'D': 3,\n",
       " 'E': 4,\n",
       " 'F': 5,\n",
       " 'G': 6,\n",
       " 'H': 7,\n",
       " 'I': 8,\n",
       " 'K': 9,\n",
       " 'L': 10,\n",
       " 'M': 11,\n",
       " 'N': 12,\n",
       " 'O': 13,\n",
       " 'P': 14,\n",
       " 'Q': 15,\n",
       " 'R': 16,\n",
       " 'S': 17,\n",
       " 'T': 18,\n",
       " 'U': 19,\n",
       " 'V': 20,\n",
       " 'W': 21,\n",
       " 'X': 22,\n",
       " 'Y': 23}"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "train_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([21, 15,  3, ..., 15,  7,  3], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "y_true = np.argmax(model.predict(train_data),axis =1)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([23], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "test_image =  image.load_img('D:\\AI ML DL\\SLD\\Testing images\\images.png',target_size=(64,64,3))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = model.predict_classes(test_image)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}